{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# BackBone"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Usage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.models import BackBone\n",
                "from src.datasets import ImageNetClassify\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "backbone = BackBone(\"ConvNeXt\") # options: ResNet18, ResNet50, TODO: ViT-B\n",
                "\n",
                "bs = 8\n",
                "ds = ImageNetClassify(\"./data/ImageNet-2012/\")\n",
                "dl = DataLoader(ds, bs)\n",
                "\n",
                "for batch in dl:\n",
                "    imgs = batch[\"img\"]\n",
                "    out = backbone(imgs)\n",
                "    for k, v in out.items():\n",
                "        print(f\"{k}: {v.shape}\")\n",
                "    break"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Validate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.models import BackBone\n",
                "from mt_pipe.src.test.external.util import make_random_nested_tens, validate_nested_obj\n",
                "\n",
                "\n",
                "bs = 8\n",
                "w, h = 224, 224\n",
                "mock_batch_conf = (bs, 3, h, w)\n",
                "\n",
                "mock_batch = make_random_nested_tens(mock_batch_conf)\n",
                "\n",
                "backbone = BackBone(\"ConvNeXt\")\n",
                "out = backbone(mock_batch)\n",
                "\n",
                "assert hasattr(backbone, \"dims\")\n",
                "assert type(backbone.dims) == dict\n",
                "assert all([type(v) == int for v in backbone.dims.values()])\n",
                "\n",
                "expected_out_conf = {\n",
                "    \"emb\": {\"shape\": (8, 768), \"dtype\": \"torch.float32\"},\n",
                "    \"l6\": {\"shape\": (8, 768, 3, 3), \"dtype\": \"torch.float32\"},\n",
                "    \"l5\": {\"shape\": (8, 384, 7, 7), \"dtype\": \"torch.float32\"},\n",
                "    \"l4\": {\"shape\": (8, 192, 14, 14), \"dtype\": \"torch.float32\"},\n",
                "    \"l3\": {\"shape\": (8, 96, 28, 28), \"dtype\": \"torch.float32\"},\n",
                "    \"l2\": {\"shape\": (8, 48, 56, 56), \"dtype\": \"torch.float32\"},\n",
                "    \"l1\": {\"shape\": (8, 48, 112, 112), \"dtype\": \"torch.float32\"},\n",
                "}\n",
                "\n",
                "valid, msg = validate_nested_obj(out, expected_out_conf)\n",
                "assert valid, msg"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# DepthDecoder"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Usage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: get the TrianFlow model from @muditha\n",
                "# from src.models.depth_decoder import DepthDecoder\n",
                "# from src.models import BackBone\n",
                "# from src.datasets.kitti import KITTIWithDepth\n",
                "# from torch.utils.data import DataLoader\n",
                "\n",
                "# ds = KITTIWithDepth(\"./data/KITTI-2012/\")\n",
                "# dl = DataLoader(ds, 8)\n",
                "\n",
                "# encoder = BackBone(\"ConvNeXt\")\n",
                "# decoder = DepthDecoder(encoder.dims)\n",
                "\n",
                "# for batch in dl:\n",
                "#     fp = encoder(batch[\"img\"])\n",
                "#     for k, v in fp.items():\n",
                "#         print(k, v.shape)\n",
                "#     pred = decoder(fp)\n",
                "#     for k, v in pred.items():\n",
                "#         print(k, v.shape)\n",
                "#     break"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: get the TrianFlow model from @muditha\n",
                "# import torch\n",
                "# from mt_pipe.src.test.external.util import validate_nested_obj\n",
                "# from src.models.depth_decoder import DepthDecoder\n",
                "\n",
                "# mock_input = {\n",
                "#     \"emb\": torch.Tensor(8, 768),\n",
                "#     \"l1\": torch.Tensor(8, 768, 1, 2),\n",
                "#     \"l2\": torch.Tensor(8, 384, 2, 4),\n",
                "#     \"l3\": torch.Tensor(8, 192, 4, 8),\n",
                "#     \"l4\": torch.Tensor(8, 96, 8, 16),\n",
                "#     \"l5\": torch.Tensor(8, 48, 16, 32),\n",
                "#     \"l6\": torch.Tensor(8, 48, 32, 64),\n",
                "# }\n",
                "# decoder = DepthDecoder(\n",
                "#     {\"l7\": 3, \"l6\": 48, \"l5\": 48, \"l4\": 96, \"l3\": 192, \"l2\": 384, \"l1\": 768},\n",
                "#     [\"l7\", \"l6\", \"l5\", \"l4\", \"l3\", \"l2\", \"l1\"],\n",
                "# )\n",
                "# out = decoder(mock_input)\n",
                "# expected_out_conf = {\n",
                "#     \"l2\": {\"shape\":(8, 1, 2, 4), \"dtype\":\"torch.float32\"},\n",
                "#     \"l3\": {\"shape\":(8, 1, 4, 8), \"dtype\":\"torch.float32\"},\n",
                "#     \"l4\": {\"shape\":(8, 1, 8, 16), \"dtype\":\"torch.float32\"},\n",
                "#     \"l5\": {\"shape\":(8, 1, 16, 32), \"dtype\":\"torch.float32\"},\n",
                "#     \"l6\": {\"shape\":(8, 1, 32, 64), \"dtype\":\"torch.float32\"},\n",
                "#     \"l7\": {\"shape\":(8, 1, 64, 128), \"dtype\":\"torch.float32\"},\n",
                "# }\n",
                "# valid, msg  = validate_nested_obj(out, expected_out_conf)\n",
                "# assert valid, msg"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# FlowDecoder"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Main"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Usage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from src.models import BackBone\n",
                "from src.datasets import KITTI\n",
                "from torch.utils.data import DataLoader\n",
                "from src.models.flow_decoder import FlowDecoder\n",
                "from src.constants import flow_img_wh\n",
                "\n",
                "device = 0\n",
                "backbone = BackBone(\"ConvNeXt\").cuda(device)\n",
                "decoder = FlowDecoder(backbone.dims).cuda(device)\n",
                "\n",
                "bs = 8\n",
                "ds = KITTI(\"./data/KITTI-2015/\", img_wh=flow_img_wh)\n",
                "dl = DataLoader(ds, bs)\n",
                "\n",
                "for batch in dl:\n",
                "    batch_one = batch[\"img1\"].cuda(device)\n",
                "    batch_two = batch[\"img2\"].cuda(device)\n",
                "\n",
                "    feature_pyramid_one = backbone(batch_one)\n",
                "    feature_pyramid_two = backbone(batch_two)\n",
                "    out = decoder(feature_pyramid_one, feature_pyramid_two, flow_img_wh)\n",
                "\n",
                "    for k, v in out.items():\n",
                "        if type(v) == torch.Tensor:\n",
                "            print(f\"{k}: {None if v is None else v.shape}\")\n",
                "        else:\n",
                "            for v2 in v:\n",
                "                print(f\"{k}: {None if v2 is None else v2.shape}\")\n",
                "    break"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from src.models.flow_decoder import FlowDecoder\n",
                "from mt_pipe.src.test.external.util import validate_nested_obj\n",
                "\n",
                "decoder = FlowDecoder({\"l1\": 48, \"l2\": 48, \"l3\": 96, \"l4\": 192, \"l5\": 384, \"l6\": 768})\n",
                "\n",
                "feature_pyramid_one = {\n",
                "    \"emb\": torch.Tensor(8, 768),\n",
                "    \"l6\": torch.Tensor(8, 768, 1, 2),\n",
                "    \"l5\": torch.Tensor(8, 384, 2, 4),\n",
                "    \"l4\": torch.Tensor(8, 192, 4, 8),\n",
                "    \"l3\": torch.Tensor(8, 96, 8, 16),\n",
                "    \"l2\": torch.Tensor(8, 48, 16, 32),\n",
                "    \"l1\": torch.Tensor(8, 48, 32, 64),\n",
                "}\n",
                "feature_pyramid_two = {\n",
                "    \"emb\": torch.Tensor(8, 768),\n",
                "    \"l6\": torch.Tensor(8, 768, 1, 2),\n",
                "    \"l5\": torch.Tensor(8, 384, 2, 4),\n",
                "    \"l4\": torch.Tensor(8, 192, 4, 8),\n",
                "    \"l3\": torch.Tensor(8, 96, 8, 16),\n",
                "    \"l2\": torch.Tensor(8, 48, 16, 32),\n",
                "    \"l1\": torch.Tensor(8, 48, 32, 64),\n",
                "}\n",
                "out = decoder(feature_pyramid_one, feature_pyramid_two, [128, 64])\n",
                "\n",
                "expected_out_conf = {\n",
                "    \"optical_flows\": [\n",
                "        {\"shape\": (8, 2, 64, 128), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 32, 64), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 16, 32), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 8, 16), \"dtype\": \"torch.float32\"},\n",
                "    ],\n",
                "    \"optical_flows_rev\": [\n",
                "        {\"shape\": (8, 2, 64, 128), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 32, 64), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 16, 32), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 8, 16), \"dtype\": \"torch.float32\"},\n",
                "    ],\n",
                "    \"img1_valid_masks\": [\n",
                "        {\"shape\": (8, 1, 64, 128), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 1, 32, 64), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 1, 16, 32), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 1, 8, 16), \"dtype\": \"torch.float32\"},\n",
                "    ],\n",
                "    \"img2_valid_masks\": [\n",
                "        {\"shape\": (8, 1, 64, 128), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 1, 32, 64), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 1, 16, 32), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 1, 8, 16), \"dtype\": \"torch.float32\"},\n",
                "    ],\n",
                "    \"fwd_flow_diff_pyramid\": [\n",
                "        {\"shape\": (8, 2, 64, 128), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 32, 64), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 16, 32), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 8, 16), \"dtype\": \"torch.float32\"},\n",
                "    ],\n",
                "    \"bwd_flow_diff_pyramid\": [\n",
                "        {\"shape\": (8, 2, 64, 128), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 32, 64), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 16, 32), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 8, 16), \"dtype\": \"torch.float32\"},\n",
                "    ],\n",
                "}\n",
                "\n",
                "valid, msg = validate_nested_obj(out, expected_out_conf)\n",
                "assert valid, msg"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
