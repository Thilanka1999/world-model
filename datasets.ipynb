{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VICReg\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import ImageNetVICReg\n",
    "from src.constants import content_img_wh\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ds = ImageNetVICReg(\"./data/ImageNet-2012/\", img_wh=content_img_wh, download=True)\n",
    "sample = ds[0]\n",
    "img1, img2 = sample[\"view1\"], sample[\"view2\"]\n",
    "print(f\"Dataset length: {len(ds)}\")\n",
    "print(f\"Image shape: {img1.shape}\")\n",
    "img1, img2 = img1.numpy(), img2.numpy()\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].imshow(img1.transpose(1, 2, 0))\n",
    "ax[1].imshow(img2.transpose(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import ImageNetVICReg\n",
    "from tqdm import tqdm\n",
    "from src.constants import content_img_wh\n",
    "from mt_pipe.src.test.external.util import validate_nested_obj\n",
    "\n",
    "expected_sample_conf = {\n",
    "    \"view1\": {\n",
    "        \"shape\": (3, *content_img_wh[::-1]),\n",
    "        \"min\": 0,\n",
    "        \"max\": 1,\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },\n",
    "    \"view2\": {\n",
    "        \"shape\": (3, *content_img_wh[::-1]),\n",
    "        \"min\": 0,\n",
    "        \"max\": 1,\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },\n",
    "}\n",
    "\n",
    "for split in [\"val\", \"train\"]:\n",
    "    ds = ImageNetVICReg(\"./data/ImageNet-2012/\", split, img_wh=content_img_wh)\n",
    "    for sample in tqdm(ds, desc=split):\n",
    "        valid, msg = validate_nested_obj(sample, expected_sample_conf)\n",
    "        assert valid, msg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import ImageNetClassify\n",
    "import matplotlib.pyplot as plt\n",
    "from src.constants import content_img_wh\n",
    "\n",
    "ds = ImageNetClassify(\"./data/ImageNet-2012/\", img_wh=content_img_wh, download=True)\n",
    "label_map = ds.label2txtlable_map\n",
    "\n",
    "sample = ds[0]\n",
    "img, lbl = sample[\"img\"], sample[\"lbl\"]\n",
    "print(f\"Label: {label_map[lbl]}\")\n",
    "print(f\"Dataset length: {len(ds)}\")\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "plt.imshow(img.numpy().transpose(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import ImageNetClassify\n",
    "from tqdm import tqdm\n",
    "from src.constants import content_img_wh\n",
    "from mt_pipe.src.test.external.util import validate_nested_obj\n",
    "\n",
    "expected_sample_conf = {\n",
    "    \"img\": {\n",
    "        \"shape\": (3, *content_img_wh[::-1]),\n",
    "        \"min\": 0,\n",
    "        \"max\": 1,\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },\n",
    "    \"lbl\": {\"dtype\": \"int\", \"min\": 0, \"max\": 999},\n",
    "}\n",
    "\n",
    "for split in [\"val\", \"train\"]:\n",
    "    ds = ImageNetClassify(\"./data/ImageNet-2012/\", split, img_wh=content_img_wh)\n",
    "    for sample in tqdm(ds, desc=split):\n",
    "        valid, msg = validate_nested_obj(sample, expected_sample_conf)\n",
    "        assert valid, msg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KITTI\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Pair"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import KITTI\n",
    "from src.constants import flow_img_wh\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ds_1 = KITTI(\"./data/KITTI-2012\", img_wh=flow_img_wh, download=\"2012\")\n",
    "ds_2 = KITTI(\"./data/KITTI-2012-multiview\", img_wh=flow_img_wh, download=\"2012_m\")\n",
    "ds_3 = KITTI(\"./data/KITTI-2015\", img_wh=flow_img_wh, download=\"2015\")\n",
    "ds_4 = KITTI(\"./data/KITTI-2015-multiview\", img_wh=flow_img_wh, download=\"2015_m\")\n",
    "ds_5 = KITTI(\"./data/KITTI\", img_wh=flow_img_wh, download=\"2011\")\n",
    "\n",
    "print(f\"KITTI 2012 length: {len(ds_1)}\")\n",
    "print(f\"KITTI 2012 Multiview length: {len(ds_2)}\")\n",
    "print(f\"KITTI 2015 length: {len(ds_3)}\")\n",
    "print(f\"KITTI 2015 Multiview length: {len(ds_4)}\")\n",
    "print(f\"KITTI Raw length: {len(ds_5)}\")\n",
    "\n",
    "sample = ds_1[0]\n",
    "img1, img2 = sample[\"img1\"], sample[\"img2\"]\n",
    "print(f\"Image shape: {tuple(img1.shape)}\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(img1.numpy().transpose(1, 2, 0))\n",
    "ax[1].imshow(img2.numpy().transpose(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from src.datasets import KITTI\n",
    "from src.constants import flow_img_wh\n",
    "from mt_pipe.src.test.external.util import validate_nested_obj\n",
    "\n",
    "expected_sample_conf = {\n",
    "    \"img1\": {\"shape\": (3, *flow_img_wh[::-1]), \"min\": 0, \"max\": 1, \"dtype\": \"torch.float32\"},\n",
    "    \"img2\": {\"shape\": (3, *flow_img_wh[::-1]), \"min\": 0, \"max\": 1, \"dtype\": \"torch.float32\"},\n",
    "}\n",
    "\n",
    "for split in [\"val\", \"train\"]:\n",
    "    for root in [\n",
    "        \"./data/KITTI-2012\",\n",
    "        \"./data/KITTI-2012-multiview\",\n",
    "        \"./data/KITTI-2015\",\n",
    "        \"./data/KITTI-2015-multiview\",\n",
    "        \"./data/KITTI\",\n",
    "    ]:\n",
    "        ds = KITTI(root, split, img_wh=flow_img_wh)\n",
    "        for sample in tqdm(ds, desc=f\"{split} {root}\"):\n",
    "            valid, msg = validate_nested_obj(sample, expected_sample_conf)\n",
    "            assert valid, msg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Pair and Calibration Matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import KITTIWithCalibration\n",
    "import matplotlib.pyplot as plt\n",
    "from src.constants import flow_img_wh\n",
    "\n",
    "ds_1 = KITTIWithCalibration(\"./data/KITTI-2012\", img_wh=flow_img_wh, download=\"2012\")\n",
    "ds_2 = KITTIWithCalibration(\"./data/KITTI\", img_wh=flow_img_wh, download=\"2011\")\n",
    "sample = ds_1[0]\n",
    "img1, img2, K, K_inv = sample[\"img1\"], sample[\"img2\"], sample[\"K\"], sample[\"K_inv\"]\n",
    "print(f\"Image shape: {tuple(img1.shape)}\")\n",
    "print(f\"Caliberation matrix shape: {K.shape}\")\n",
    "print(f\"KITTI Raw Dataset length: {len(ds_1)}\")\n",
    "print(f\"KITTI 2012 Dataset length: {len(ds_2)}\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(img1.numpy().transpose(1, 2, 0))\n",
    "ax[1].imshow(img2.numpy().transpose(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from src.datasets import KITTIWithCalibration\n",
    "from src.constants import flow_img_wh\n",
    "from mt_pipe.src.test.external.util import validate_nested_obj\n",
    "\n",
    "expected_sample_conf = {\n",
    "    \"img1\": {\n",
    "        \"shape\": (3, *flow_img_wh[::-1]),\n",
    "        \"min\": 0,\n",
    "        \"max\": 1,\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },\n",
    "    \"img2\": {\n",
    "        \"shape\": (3, *flow_img_wh[::-1]),\n",
    "        \"min\": 0,\n",
    "        \"max\": 1,\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },\n",
    "    \"K\": {\n",
    "        \"shape\": (1, 3, 3),\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },  # TODO: is there a min and max for K and K_inv?\n",
    "    \"K_inv\": {\"shape\": (1, 3, 3), \"dtype\": \"torch.float32\"},\n",
    "}\n",
    "\n",
    "# TODO: Fix the following warning. Occurs when using the kitti_raw\n",
    "# TODO: error while iterating\n",
    "#   /home/avishka/anaconda3/envs/wm/lib/python3.10/site-packages/numpy/linalg/linalg.py:562: RuntimeWarning: overflow encountered in cast\n",
    "#   return wrap(ainv.astype(result_t, copy=False))\n",
    "for split in [\"val\", \"train\"]:\n",
    "    for root in [\"./data/KITTI\", \"./data/KITTI-2012\"]:\n",
    "        ds = KITTIWithCalibration(root, split, img_wh=flow_img_wh)\n",
    "        for sample in tqdm(ds, desc=f\"{split} {root}\"):\n",
    "            valid, msg = validate_nested_obj(sample, expected_sample_conf)\n",
    "            assert valid, msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image with DepthMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import KITTIWithDepth\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from src.constants import flow_img_wh\n",
    "\n",
    "ds = KITTIWithDepth(\"./data/KITTI-2012/\", img_wh=flow_img_wh, download=\"2012\")\n",
    "\n",
    "sample = ds[100]\n",
    "img, depth_map = sample[\"img\"], sample[\"depth_map\"]\n",
    "print(f\"Image shape: {tuple(img.shape)}\")\n",
    "print(f\"Flowmap shape: {depth_map.shape}\")\n",
    "print(f\"KITTI 2012 Dataset length: {len(ds)}\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(9, 3))\n",
    "ax[0].imshow(img.numpy().transpose(1, 2, 0))\n",
    "ax[1].imshow(depth_map.numpy().transpose(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from src.datasets import KITTIWithDepth\n",
    "from src.constants import flow_img_wh\n",
    "from mt_pipe.src.test.external.util import validate_nested_obj\n",
    "\n",
    "expected_sample_conf = {\n",
    "    \"img\": {\n",
    "        \"shape\": (3, *flow_img_wh[::-1]),\n",
    "        \"min\": 0,\n",
    "        \"max\": 1,\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },\n",
    "    \"depth_map\": {\n",
    "        \"shape\": (1, *flow_img_wh[::-1]),\n",
    "        \"dtype\": \"torch.float32\",\n",
    "        \"min\": 0\n",
    "    }, \n",
    "}\n",
    "\n",
    "for split in [\"train\"]:\n",
    "    for root in [\n",
    "        \"./data/KITTI-2012\",\n",
    "        \"./data/KITTI-2015\",\n",
    "        \"./data/KITTI\",\n",
    "    ]:\n",
    "        ds = KITTIWithDepth(root, split, img_wh=flow_img_wh)\n",
    "        for sample in tqdm(ds, desc=f\"{split} {root}\"):\n",
    "            valid, msg = validate_nested_obj(sample, expected_sample_conf)\n",
    "            assert valid, msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KITTI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import KITTIWithFlow\n",
    "from src.constants import flow_img_wh\n",
    "from src.util.visualize import plot_warp\n",
    "\n",
    "ds_1 = KITTIWithFlow(\"./data/KITTI-2012\", img_wh=flow_img_wh, download=\"2012\")\n",
    "ds_2 = KITTIWithFlow(\"./data/KITTI-2015\", img_wh=flow_img_wh, download=\"2015\")\n",
    "sample = ds_1[0]\n",
    "img1, img2, flow_map, valid_mask, occ_mask = (\n",
    "    sample[\"img1\"],\n",
    "    sample[\"img2\"],\n",
    "    sample[\"flow_gt\"],\n",
    "    sample[\"valid\"],\n",
    "    sample[\"occ_gt\"],\n",
    ")\n",
    "print(f\"Image shape: {tuple(img1.shape)}\")\n",
    "print(f\"Flowmap shape: {flow_map.shape}\")\n",
    "print(f\"KITTI 2012 Dataset length: {len(ds_1)}\")\n",
    "print(f\"KITTI 2015 Dataset length: {len(ds_2)}\")\n",
    "print(\"valid_mask shape : \", valid_mask.shape)\n",
    "print(\"occ_mask shape :\", occ_mask.shape)\n",
    "\n",
    "plot_warp(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from src.datasets import KITTIWithFlow\n",
    "from src.constants import flow_img_wh\n",
    "from mt_pipe.src.test.external.util import validate_nested_obj\n",
    "\n",
    "expected_sample_conf = {\n",
    "    \"img1\": {\n",
    "        \"shape\": (3, *flow_img_wh[::-1]),\n",
    "        \"min\": 0,\n",
    "        \"max\": 1,\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },\n",
    "    \"img2\": {\n",
    "        \"shape\": (3, *flow_img_wh[::-1]),\n",
    "        \"min\": 0,\n",
    "        \"max\": 1,\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },\n",
    "    \"flow_gt\": {  # TODO: is there a min and max for flow maps?\n",
    "        \"shape\": (2, *flow_img_wh[::-1]),\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },\n",
    "    \"valid\": {\n",
    "        \"shape\": flow_img_wh[::-1],\n",
    "        \"unique\": [0, 1],\n",
    "        \"dtype\": \"numpy.float32\",\n",
    "    },\n",
    "    \"occ_gt\": {\n",
    "        \"shape\": flow_img_wh[::-1],\n",
    "        \"unique\": [0, 1],\n",
    "        \"dtype\": \"numpy.float32\",\n",
    "    },\n",
    "}\n",
    "\n",
    "for split in [\"train\"]:\n",
    "    for root in [\n",
    "        \"./data/KITTI-2012\",\n",
    "        \"./data/KITTI-2015\",\n",
    "    ]:\n",
    "        ds = KITTIWithFlow(root, split, img_wh=flow_img_wh)\n",
    "        for sample in tqdm(ds, desc=f\"{split} {root}\"):\n",
    "            valid, msg = validate_nested_obj(sample, expected_sample_conf)\n",
    "            assert valid, msg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HD1K\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import HD1K\n",
    "from src.constants import flow_img_wh\n",
    "from src.util.visualize import plot_warp\n",
    "\n",
    "ds = HD1K(\"./data/HD1K/\", \"train\", img_wh=flow_img_wh, download=True)\n",
    "sample = ds[0]\n",
    "img1, img2, flow, occs = sample[\"img1\"], sample[\"img2\"], sample[\"flow_gt\"], sample[\"occ_gt\"]\n",
    "\n",
    "print(f\"Image1 shape: {tuple(img1.shape)}\")\n",
    "print(f\"Image2 shape: {tuple(img2.shape)}\")\n",
    "print(f\"Flow shape: {tuple(flow.shape)}\")\n",
    "print(f\"Occlusions shape: {tuple(occs.shape)}\")\n",
    "print(f\"Dataset length: {len(ds)}\")\n",
    "\n",
    "plot_warp(sample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from src.datasets import HD1K\n",
    "from src.constants import flow_img_wh\n",
    "from mt_pipe.src.test.external.util import validate_nested_obj\n",
    "\n",
    "expected_sample_conf = {\n",
    "    \"img1\": {\n",
    "        \"shape\": (3, *flow_img_wh[::-1]),\n",
    "        \"min\": 0,\n",
    "        \"max\": 1,\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },\n",
    "    \"img2\": {\n",
    "        \"shape\": (3, *flow_img_wh[::-1]),\n",
    "        \"min\": 0,\n",
    "        \"max\": 1,\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },\n",
    "    \"flow_gt\": {  # TODO: is there a min and max for flow maps?\n",
    "        \"shape\": (2, *flow_img_wh[::-1]),\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },\n",
    "    \"valid\": {\n",
    "        \"shape\": flow_img_wh[::-1],\n",
    "        \"unique\": [0, 1],\n",
    "        \"dtype\": \"numpy.float32\",\n",
    "    },\n",
    "    \"occ_gt\": {\n",
    "        \"shape\": flow_img_wh[::-1],\n",
    "        \"unique\": [0, 1],\n",
    "        \"dtype\": \"numpy.float32\",\n",
    "    },\n",
    "}\n",
    "\n",
    "for split in [\"val\", \"train\"]:\n",
    "    ds = HD1K(\"./data/HD1K/\", split, img_wh=flow_img_wh)\n",
    "    for sample in tqdm(ds, desc=split):\n",
    "        valid, msg = validate_nested_obj(sample, expected_sample_conf)\n",
    "        assert valid, msg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPISintel\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import MPISintel\n",
    "from src.util.visualize import plot_warp\n",
    "import numpy as np\n",
    "from src.constants import flow_img_wh\n",
    "\n",
    "dataset = MPISintel(\"./data/MPISintel/\", \"train\", flow_img_wh)\n",
    "idx = np.random.randint(0, len(dataset))\n",
    "print(f\"Index: {idx}\")\n",
    "sample = dataset[idx]\n",
    "plot_warp(sample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import MPISintel\n",
    "from tqdm import tqdm\n",
    "from src.constants import flow_img_wh\n",
    "from mt_pipe.src.test.external.util import validate_nested_obj\n",
    "\n",
    "expected_sample_conf = {\n",
    "    \"img1\": {\n",
    "        \"shape\": (3, *flow_img_wh[::-1]),\n",
    "        \"min\": 0,\n",
    "        \"max\": 1,\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },\n",
    "    \"img2\": {\n",
    "        \"shape\": (3, *flow_img_wh[::-1]),\n",
    "        \"min\": 0,\n",
    "        \"max\": 1,\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },\n",
    "    \"flow_gt\": {\n",
    "        \"shape\": (2, *flow_img_wh[::-1]),\n",
    "        \"min\": -max(flow_img_wh),\n",
    "        \"max\": max(flow_img_wh),\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },\n",
    "    \"occ_gt\": {\n",
    "        \"shape\": flow_img_wh[::-1],\n",
    "        \"unique\": [0, 1],\n",
    "        \"dtype\": \"numpy.float32\",\n",
    "    },\n",
    "    \"valid\": {\n",
    "        \"shape\": flow_img_wh[::-1],\n",
    "        \"unique\": [0, 1],\n",
    "        \"dtype\": \"numpy.float32\",\n",
    "    },\n",
    "}\n",
    "\n",
    "for split in [\"train\"]:\n",
    "    ds = MPISintel(\"./data/MPISintel/\", split, img_wh=flow_img_wh)\n",
    "    for sample in tqdm(ds, desc=split):\n",
    "        valid, msg = validate_nested_obj(sample, expected_sample_conf)\n",
    "        assert valid, msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FlyingThings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import FlyingThings\n",
    "import matplotlib.pyplot as plt\n",
    "from src.constants import flow_img_wh\n",
    "\n",
    "ds = FlyingThings(\n",
    "    \"./data/FlyingThings/\", \"train\", img_wh=flow_img_wh, download=True\n",
    ")\n",
    "sample = ds[0]\n",
    "img1, img2 = sample[\"img1\"], sample[\"img2\"]\n",
    "\n",
    "print(f\"Image1 shape: {tuple(img1.shape)}\")\n",
    "print(f\"Image2 shape: {tuple(img2.shape)}\")\n",
    "print(f\"Dataset length: {len(ds)}\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(img1.numpy().transpose(1, 2, 0))\n",
    "ax[1].imshow(img2.numpy().transpose(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from src.datasets import FlyingThings\n",
    "from src.constants import flow_img_wh\n",
    "from mt_pipe.src.test.external.util import validate_nested_obj\n",
    "\n",
    "expected_sample_conf = {\n",
    "    \"img1\": {\n",
    "        \"shape\": (3, *flow_img_wh[::-1]),\n",
    "        \"min\": 0,\n",
    "        \"max\": 1,\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },\n",
    "    \"img2\": {\n",
    "        \"shape\": (3, *flow_img_wh[::-1]),\n",
    "        \"min\": 0,\n",
    "        \"max\": 1,\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },\n",
    "}\n",
    "\n",
    "for split in [\"val\", \"train\"]:\n",
    "    ds = FlyingThings(\"./data/FlyingThings/\", split, img_wh=flow_img_wh)\n",
    "    for sample in tqdm(ds, desc=split):\n",
    "        valid, msg = validate_nested_obj(sample, expected_sample_conf)\n",
    "        assert valid, msg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FlyingChairs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import FlyingChairs\n",
    "from src.util.visualize import plot_warp\n",
    "import numpy as np\n",
    "from src.constants import flow_img_wh\n",
    "\n",
    "dataset = FlyingChairs(\"./data/FlyingChairs/\", \"train\", None)\n",
    "idx = np.random.randint(0, len(dataset))\n",
    "print(f\"Index: {idx}\")\n",
    "sample = dataset[idx]\n",
    "img1, img2, flow, occs = (\n",
    "    sample[\"img1\"],\n",
    "    sample[\"img2\"],\n",
    "    sample[\"flow_gt\"],\n",
    "    sample[\"occ_gt\"],\n",
    ")\n",
    "\n",
    "print(f\"Image1 shape: {tuple(img1.shape)}\")\n",
    "print(f\"Image2 shape: {tuple(img2.shape)}\")\n",
    "print(f\"Flow shape: {tuple(flow.shape)}\")\n",
    "print(f\"Occlusions: {tuple(occs.shape)}\")\n",
    "\n",
    "plot_warp(sample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from src.datasets import FlyingChairs\n",
    "from src.constants import flow_img_wh\n",
    "from mt_pipe.src.test.external.util import validate_nested_obj\n",
    "\n",
    "expected_sample_conf = {\n",
    "    \"img1\": {\n",
    "        \"shape\": (3, *flow_img_wh[::-1]),\n",
    "        \"min\": 0,\n",
    "        \"max\": 1,\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },\n",
    "    \"img2\": {\n",
    "        \"shape\": (3, *flow_img_wh[::-1]),\n",
    "        \"min\": 0,\n",
    "        \"max\": 1,\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },\n",
    "    \"flow_gt\": {\n",
    "        \"shape\": (2, *flow_img_wh[::-1]),\n",
    "        \"min\": -max(flow_img_wh),\n",
    "        \"max\": max(flow_img_wh),\n",
    "        \"dtype\": \"torch.float32\",\n",
    "    },\n",
    "    \"occ_gt\": None,\n",
    "    \"valid\": None,\n",
    "}\n",
    "\n",
    "for split in [\"val\", \"train\"]:\n",
    "    ds = FlyingChairs(\"./data/FlyingChairs/\", split, img_wh=flow_img_wh)\n",
    "    for sample in tqdm(ds, desc=split):\n",
    "        valid, msg = validate_nested_obj(sample, expected_sample_conf)\n",
    "        assert valid, msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConcatSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mt_pipe.src.datasets import ConcatSet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ds = ConcatSet(\n",
    "    root=[\"./data/FlyingChairs\", \"./data/FlyingThings\"],\n",
    "    conf=[\n",
    "        {\"target\": \"src.datasets.FlyingChairs\", \"reps\": 1},\n",
    "        {\"target\": \"src.datasets.FlyingThings\", \"reps\": 1},\n",
    "    ],\n",
    ")\n",
    "\n",
    "sample = ds[0]\n",
    "img1, img2 = sample[\"img1\"], sample[\"img2\"]\n",
    "\n",
    "print(f\"Image1 shape: {tuple(img1.shape)}\")\n",
    "print(f\"Image2 shape: {tuple(img2.shape)}\")\n",
    "print(f\"Dataset length: {len(ds)}\")\n",
    "\n",
    "fig, ax = plt.subplots(2)\n",
    "ax[0].imshow(img1.numpy().transpose(1, 2, 0))\n",
    "ax[1].imshow(img2.numpy().transpose(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import ImageNetVICReg, KITTIWithCalibration\n",
    "from mt_pipe.src.util.data import ParallelDataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ds1 = ImageNetVICReg(\"./data/ImageNet-2012/\")\n",
    "ds2 = KITTIWithCalibration(\"./data/KITTI-2012/\")\n",
    "dl1 = DataLoader(ds1, 256)\n",
    "dl2 = DataLoader(ds2, 8)\n",
    "dl3 = ParallelDataLoader([dl1, dl2])\n",
    "\n",
    "print(len(dl1), len(dl2), len(dl3))\n",
    "for batch in dl3:\n",
    "    print(batch.keys())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import COCOSegment\n",
    "from src.constants import content_img_wh\n",
    "from src.util.visualize import plot_segs\n",
    "\n",
    "ds = COCOSegment(\"./data/COCO-2017\", img_wh=None, download=True)\n",
    "classes = ds.classes\n",
    "sample = ds[0]\n",
    "\n",
    "print(f\"Dataset length: {len(ds)}\")\n",
    "plot_segs(sample, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import COCOSegment\n",
    "from tqdm import tqdm\n",
    "from mt_pipe.src.test.external.util import validate_nested_obj\n",
    "from src.constants import content_img_wh\n",
    "\n",
    "\n",
    "expected_sample_conf = {\n",
    "    \"img\":{\n",
    "        \"dtype\": \"torch.float32\",\n",
    "        \"max\": 1,\n",
    "        \"min\": 0,\n",
    "        \"shape\": [3, *content_img_wh[::-1]],\n",
    "        },\n",
    "    \"seg\":{\n",
    "        \"dtype\": \"torch.float32\",\n",
    "        \"shape\": content_img_wh[::-1],\n",
    "        \"unique_range\": [0, 80],}\n",
    "}\n",
    "\n",
    "for split in [\"val\", \"train\"]:\n",
    "    ds = COCOSegment(\"./data/COCO-2017\", split, img_wh=content_img_wh)\n",
    "    for sample in tqdm(ds, desc=split):\n",
    "        valid, msg = validate_nested_obj(sample, expected_sample_conf)\n",
    "        assert valid, msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PascalVOC 2012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import PascalVOC\n",
    "from src.util.visualize import plot_segs\n",
    "from src.constants import flow_img_wh\n",
    "\n",
    "ds = PascalVOC(\"./data/PascalVOC-2012\", img_wh=flow_img_wh, download=True)\n",
    "classes = ds.class_names\n",
    "\n",
    "sample = ds[0]\n",
    "img, seg = sample[\"img\"], sample[\"seg\"]\n",
    "\n",
    "print(f\"Dataset length: {len(ds)}\")\n",
    "plot_segs(sample, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import PascalVOC\n",
    "from tqdm import tqdm\n",
    "from mt_pipe.src.test.external.util import validate_nested_obj\n",
    "from src.constants import flow_img_wh\n",
    "\n",
    "\n",
    "expected_sample_conf = {\n",
    "    \"img\": {\n",
    "        \"dtype\": \"torch.float32\",\n",
    "        \"max\": 1,\n",
    "        \"min\": 0,\n",
    "        \"shape\": [3, *flow_img_wh[::-1]],\n",
    "    },\n",
    "    \"seg\": {\n",
    "        \"dtype\": \"torch.float32\",\n",
    "        \"shape\": flow_img_wh[::-1],\n",
    "        \"unique_range\": [0, 21],\n",
    "    },\n",
    "}\n",
    "\n",
    "for split in [\"val\", \"train\"]:\n",
    "    ds = PascalVOC(\"./data/PascalVOC-2012\", split, img_wh=flow_img_wh)\n",
    "    for sample in tqdm(ds, desc=split):\n",
    "        valid, msg = validate_nested_obj(sample, expected_sample_conf)\n",
    "        assert valid, msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Davis 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import Davis\n",
    "from src.util.visualize import plot_segs\n",
    "from src.constants import flow_img_wh\n",
    "\n",
    "ds = Davis(\"./data/Davis\", img_wh=flow_img_wh, download=True)\n",
    "classes = ds.file_contents\n",
    "\n",
    "sample = ds[0]\n",
    "img, seg = sample[\"img\"], sample[\"seg\"]\n",
    "\n",
    "print(f\"Dataset length: {len(ds)}\")\n",
    "plot_segs(sample, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import Davis\n",
    "from tqdm import tqdm\n",
    "from mt_pipe.src.test.external.util import validate_nested_obj\n",
    "from src.constants import flow_img_wh\n",
    "\n",
    "\n",
    "expected_sample_conf = {\n",
    "    \"img\": {\n",
    "        \"dtype\": \"torch.float32\",\n",
    "        \"max\": 1,\n",
    "        \"min\": 0,\n",
    "        \"shape\": [3, *flow_img_wh[::-1]],\n",
    "    },\n",
    "    \"seg\": {\n",
    "        \"dtype\": \"torch.float32\",\n",
    "        \"shape\": flow_img_wh[::-1],\n",
    "        \"unique_range\": [0, 60],\n",
    "    },\n",
    "}\n",
    "\n",
    "for split in [\"val\", \"train\"]:\n",
    "    ds = Davis(\"./data/Davis\", img_wh=flow_img_wh, download=True)\n",
    "    for sample in tqdm(ds, desc=split):\n",
    "        valid, msg = validate_nested_obj(sample, expected_sample_conf)\n",
    "        assert valid, msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cityscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.datasets import Cityscape\n",
    "# from src.util.visualize import plot_segs\n",
    "# from src.constants import flow_img_wh\n",
    "\n",
    "# ds = Cityscape(\"./data/Cityscapes\", img_wh=flow_img_wh, download=True)\n",
    "# classes = ds.class_names\n",
    "\n",
    "# sample = ds[0]\n",
    "# img, seg = sample[\"img\"], sample[\"seg\"]\n",
    "\n",
    "# print(f\"Dataset length: {len(ds)}\")\n",
    "# plot_segs(sample, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.datasets import Cityscape\n",
    "# from tqdm import tqdm\n",
    "# from mt_pipe.src.test.external.util import validate_nested_obj\n",
    "# from src.constants import flow_img_wh\n",
    "\n",
    "\n",
    "# expected_sample_conf = {\n",
    "#     \"img\": {\n",
    "#         \"shape\": (3, *flow_img_wh[::-1]),\n",
    "#         \"min\": 0,\n",
    "#         \"max\": 1,\n",
    "#         \"dtype\": \"torch.float32\",\n",
    "#     },\n",
    "#     \"seg\": {\n",
    "#         \"shape\": (flow_img_wh[::-1]),\n",
    "#         \"min\": 0,\n",
    "#         \"max\": (len(classes)+1),\n",
    "#         \"dtype\": \"torch.float32\",\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# for split in [\"val\", \"train\", \"test\"]:\n",
    "#     ds = Cityscape(\"./data/Cityscapes\", split, img_wh=flow_img_wh)\n",
    "#     for sample in tqdm(ds, desc=split):\n",
    "#         valid, msg = validate_nested_obj(sample, expected_sample_conf)\n",
    "#         assert valid, msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADE20K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.datasets import ADE20k\n",
    "# import matplotlib.pyplot as plt\n",
    "# from src.constants import flow_img_wh\n",
    "\n",
    "# ds = ADE20k(\"./data/ADE20K-2021\", img_wh=flow_img_wh, download=True)\n",
    "# classes = ds.name_list\n",
    "\n",
    "# sample = ds[0]\n",
    "# img, seg = sample[\"img\"], sample[\"seg\"]\n",
    "\n",
    "# print(f\"Dataset length: {len(ds)}\")\n",
    "# print(f\"Image shape: {img.shape}, Image min: {img.min()}, Image max: {img.max()}\")\n",
    "# print(f\"Segment shape: {seg.shape}, Segment min: {seg.min()}, Segment max: {seg.max()}\")\n",
    "\n",
    "# img, seg = img.numpy(), seg.numpy()\n",
    "# window_idx = classes.index(\"windowpane, window\")\n",
    "# podium_idx = classes.index(\"podium\")\n",
    "\n",
    "# fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "# ax[0].imshow(img.transpose(1, 2, 0))\n",
    "# ax[0].set_title(\"Original Image\")\n",
    "# ax[1].imshow(seg[window_idx])\n",
    "# ax[1].set_title(\"Window\")\n",
    "# ax[2].imshow(seg[podium_idx])\n",
    "# ax[2].set_title(\"Podium\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# ds = ADE20k(\"./data/ADE20K-2021\", \"val\")\n",
    "# sample = ds[0]\n",
    "# img, seg = sample[\"img\"], sample[\"seg\"]\n",
    "\n",
    "# print(f\"Dataset length: {len(ds)}\")\n",
    "# print(f\"Image shape: {img.shape}, Image min: {img.min()}, Image max: {img.max()}\")\n",
    "# print(\n",
    "#     f\"Segment shape: {seg.shape}, Segment min: {seg.min()}, Segment max: {seg.max()}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.datasets import ADE20k\n",
    "# from tqdm import tqdm\n",
    "# from mt_pipe.src.test.external.util import validate_nested_obj\n",
    "# from src.constants import flow_img_wh\n",
    "\n",
    "\n",
    "# expected_sample_conf = {\n",
    "#     \"img\": {\n",
    "#         \"shape\": (3, *flow_img_wh[::-1]),\n",
    "#         \"min\": 0,\n",
    "#         \"max\": 1,\n",
    "#         \"dtype\": \"torch.float32\",\n",
    "#     },\n",
    "#     \"seg\": {\n",
    "#         \"shape\": (3687, *flow_img_wh[::-1]),\n",
    "#         \"min\": 0,\n",
    "#         \"max\": 1,\n",
    "#         \"dtype\": \"torch.float32\",\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# for split in [\"val\", \"train\"]:\n",
    "#     ds = ADE20k(\"./data/ADE20K-2021\", split, img_wh=flow_img_wh)\n",
    "#     for sample in tqdm(ds, desc=split):\n",
    "#         valid, msg = validate_nested_obj(sample, expected_sample_conf)\n",
    "#         assert valid, msg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
