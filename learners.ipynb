{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ContentLearner"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Usage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.models import BackBone\n",
                "from src.learners import ContentLearner\n",
                "from src.datasets import ImageNetVICReg\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "bs = 8\n",
                "ds = ImageNetVICReg(\"./data/ImageNet-2012/\")\n",
                "dl = DataLoader(ds, bs)\n",
                "\n",
                "backbone = BackBone(\"ConvNeXt\")\n",
                "ln = ContentLearner(backbone)\n",
                "ln.set_devices([0, 1])\n",
                "\n",
                "for batch in dl:\n",
                "    out = ln(batch)\n",
                "    for k, v in out.items():\n",
                "        print(f\"{k}: {v.shape}\")\n",
                "    break"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Validate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from src.models import BackBone\n",
                "from src.learners import ContentLearner\n",
                "from src.constants import content_img_wh\n",
                "from mt_pipe.src.test.external.util import validate_nested_obj\n",
                "\n",
                "bs = 8\n",
                "\n",
                "backbone = BackBone(\"ConvNeXt\").cuda(0)\n",
                "ln = ContentLearner(backbone)\n",
                "ln.set_devices([0, 1])\n",
                "\n",
                "mock_batch = {\n",
                "    \"view1\": torch.Tensor(bs, 3, *content_img_wh[::-1]),\n",
                "    \"view2\": torch.Tensor(bs, 3, *content_img_wh[::-1]),\n",
                "}\n",
                "\n",
                "out = ln(mock_batch)\n",
                "expected_out_conf = {\n",
                "    \"X_one\": {\"shape\": (bs, 768), \"dtype\": \"torch.float32\"},\n",
                "    \"X_two\": {\"shape\": (bs, 768), \"dtype\": \"torch.float32\"},\n",
                "    \"Y_one\": {\"shape\": (bs, 8192), \"dtype\": \"torch.float32\"},\n",
                "    \"Y_two\": {\"shape\": (bs, 8192), \"dtype\": \"torch.float32\"},\n",
                "}\n",
                "\n",
                "valid, msg = validate_nested_obj(out, expected_out_conf)\n",
                "assert valid, msg"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# FlowLearner"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Usage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.learners import FlowLearner\n",
                "from src.datasets import MPISintel\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "bs = 8\n",
                "ds = MPISintel(\"./data/MPISintel/\", img_wh=[832, 256])\n",
                "dl = DataLoader(ds, bs)\n",
                "ln = FlowLearner({\"target\": \"src.models.encoders.PWCEncoder\"})\n",
                "ln.set_devices([0, 1])\n",
                "\n",
                "batch = next(iter(dl))\n",
                "info = ln(batch)\n",
                "for k, v in info.items():\n",
                "    print(f\"{k}: {type(v)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Validate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from src.models import BackBone\n",
                "from src.learners import FlowLearner\n",
                "from mt_pipe.src.test.external.util import validate_nested_obj\n",
                "\n",
                "bs = 8\n",
                "img_hw = [64,128]\n",
                "\n",
                "backbone = BackBone(\"ConvNeXt\").cuda(1)\n",
                "ln = FlowLearner(backbone)\n",
                "ln.set_devices([1, 1])\n",
                "\n",
                "mock_batch = {\n",
                "    \"img1\": torch.Tensor(bs, 3, *img_hw),\n",
                "    \"img2\": torch.Tensor(bs, 3, *img_hw),\n",
                "}\n",
                "expected_out_conf = {\n",
                "    \"flow_pred\": {\"shape\": (8, 2, 64, 128), \"dtype\": \"torch.float32\"},\n",
                "    \"feature_pyramid_one\": {\n",
                "        \"emb\": {\"shape\": (8, 768), \"dtype\": \"torch.float32\"},\n",
                "        \"l6\": {\"shape\": (8, 768, 1, 2), \"dtype\": \"torch.float32\"},\n",
                "        \"l5\": {\"shape\": (8, 384, 2, 4), \"dtype\": \"torch.float32\"},\n",
                "        \"l4\": {\"shape\": (8, 192, 4, 8), \"dtype\": \"torch.float32\"},\n",
                "        \"l3\": {\"shape\": (8, 96, 8, 16), \"dtype\": \"torch.float32\"},\n",
                "        \"l2\": {\"shape\": (8, 48, 16, 32), \"dtype\": \"torch.float32\"},\n",
                "        \"l1\": {\"shape\": (8, 48, 32, 64), \"dtype\": \"torch.float32\"},\n",
                "    },\n",
                "    \"feature_pyramid_two\": {\n",
                "        \"emb\": {\"shape\": (8, 768), \"dtype\": \"torch.float32\"},\n",
                "        \"l6\": {\"shape\": (8, 768, 1, 2), \"dtype\": \"torch.float32\"},\n",
                "        \"l5\": {\"shape\": (8, 384, 2, 4), \"dtype\": \"torch.float32\"},\n",
                "        \"l4\": {\"shape\": (8, 192, 4, 8), \"dtype\": \"torch.float32\"},\n",
                "        \"l3\": {\"shape\": (8, 96, 8, 16), \"dtype\": \"torch.float32\"},\n",
                "        \"l2\": {\"shape\": (8, 48, 16, 32), \"dtype\": \"torch.float32\"},\n",
                "        \"l1\": {\"shape\": (8, 48, 32, 64), \"dtype\": \"torch.float32\"},\n",
                "    },\n",
                "    \"optical_flows\": [\n",
                "        {\"shape\": (8, 2, 64, 128), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 32, 64), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 16, 32), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 8, 16), \"dtype\": \"torch.float32\"},\n",
                "    ],\n",
                "    \"optical_flows_rev\": [\n",
                "        {\"shape\": (8, 2, 64, 128), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 32, 64), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 16, 32), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 8, 16), \"dtype\": \"torch.float32\"},\n",
                "    ],\n",
                "    \"img1_valid_masks\": [\n",
                "        {\"shape\": (8, 1, 64, 128), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 1, 32, 64), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 1, 16, 32), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 1, 8, 16), \"dtype\": \"torch.float32\"},\n",
                "    ],\n",
                "    \"img2_valid_masks\": [\n",
                "        {\"shape\": (8, 1, 64, 128), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 1, 32, 64), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 1, 16, 32), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 1, 8, 16), \"dtype\": \"torch.float32\"},\n",
                "    ],\n",
                "    \"fwd_flow_diff_pyramid\": [\n",
                "        {\"shape\": (8, 2, 64, 128), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 32, 64), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 16, 32), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 8, 16), \"dtype\": \"torch.float32\"},\n",
                "    ],\n",
                "    \"bwd_flow_diff_pyramid\": [\n",
                "        {\"shape\": (8, 2, 64, 128), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 32, 64), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 16, 32), \"dtype\": \"torch.float32\"},\n",
                "        {\"shape\": (8, 2, 8, 16), \"dtype\": \"torch.float32\"},\n",
                "    ],\n",
                "}\n",
                "\n",
                "out = ln(mock_batch)\n",
                "valid, msg = validate_nested_obj(out, expected_out_conf)\n",
                "assert valid, msg"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# DepthLearner"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Usage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from src.learners import DepthLearner\n",
                "# from src.datasets.kitti import KITTIWithDepth\n",
                "# from torch.utils.data import DataLoader\n",
                "# from src.models import BackBone\n",
                "\n",
                "# bs = 4\n",
                "# ds = KITTIWithDepth(\"./data/KITTI-2012/\")\n",
                "# dl = DataLoader(ds, bs)\n",
                "\n",
                "# backbone = BackBone(\"ConvNeXt\").cuda(0)\n",
                "# ln = DepthLearner(backbone)\n",
                "# ln.set_devices([0, 1])\n",
                "\n",
                "# for batch in dl:\n",
                "#     out = ln(batch)\n",
                "#     for k, v in out.items():\n",
                "#         print(f\"{k}: {v.shape}\")\n",
                "#     break"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Validate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# import torch\n",
                "# from src.learners import DepthLearner\n",
                "# from src.models import BackBone\n",
                "# from src.constants import flow_img_wh\n",
                "# from mt_pipe.src.test.external.util import validate_nested_obj\n",
                "\n",
                "\n",
                "# bs = 4\n",
                "\n",
                "# backbone = BackBone(\"ConvNeXt\").cuda(0)\n",
                "# ln = DepthLearner(backbone)\n",
                "# ln.set_devices([0, 1])\n",
                "\n",
                "# mock_batch = {\n",
                "#     \"img\": torch.Tensor(4, 3, *flow_img_wh[::-1]),\n",
                "#     \"depth_map\": torch.Tensor(4, 1, *flow_img_wh[::-1]),\n",
                "# }\n",
                "# out = ln(mock_batch)\n",
                "\n",
                "# expected_out_conf = {\n",
                "#     \"l2\": {\n",
                "#         \"shape\": (bs, 1, *[int(d / 2**5) for d in flow_img_wh[::-1]]),\n",
                "#         \"dtype\": \"torch.float32\",\n",
                "#     },\n",
                "#     \"l3\": {\n",
                "#         \"shape\": (bs, 1, *[int(d / 2**4) for d in flow_img_wh[::-1]]),\n",
                "#         \"dtype\": \"torch.float32\",\n",
                "#     },\n",
                "#     \"l4\": {\n",
                "#         \"shape\": (bs, 1, *[int(d / 2**3) for d in flow_img_wh[::-1]]),\n",
                "#         \"dtype\": \"torch.float32\",\n",
                "#     },\n",
                "#     \"l5\": {\n",
                "#         \"shape\": (bs, 1, *[int(d / 2**2) for d in flow_img_wh[::-1]]),\n",
                "#         \"dtype\": \"torch.float32\",\n",
                "#     },\n",
                "#     \"l6\": {\n",
                "#         \"shape\": (bs, 1, *[int(d / 2**1) for d in flow_img_wh[::-1]]),\n",
                "#         \"dtype\": \"torch.float32\",\n",
                "#     },\n",
                "#     \"l7\": {\"shape\": (bs, 1, *flow_img_wh[::-1]), \"dtype\": \"torch.float32\"},\n",
                "#     \"pred\": {\"shape\": (bs, 1, *flow_img_wh[::-1]), \"dtype\": \"torch.float32\"},\n",
                "# }\n",
                "# valid, msg = validate_nested_obj(out, expected_out_conf)\n",
                "# assert valid, msg"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# All Learners"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Usage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from mt_pipe.src.util.learner_mux import LearnerMux\n",
                "from src.datasets import KITTIWithCalibration, ImageNetVICReg\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "ds1 = KITTIWithCalibration(\"./data/KITTI-2012\", img_wh=[128,64])\n",
                "dl1 = DataLoader(ds1, 4)\n",
                "ds2 = ImageNetVICReg(\"./data/ImageNet-2012\", img_wh=[128,64])\n",
                "dl2 = DataLoader(ds2, 4)\n",
                "\n",
                "ln = LearnerMux(\n",
                "    chldrn={\n",
                "        \"flow_learner\": {\n",
                "            \"target\": \"src.learners.FlowLearner\",\n",
                "            \"out_map\": {\"flow_path\": \"flow\"},\n",
                "        },\n",
                "        # \"depth_learner\": {\n",
                "        #     \"target\": \"src.learners.DepthLearner\",\n",
                "        #     \"in_map\": {\n",
                "        #         \"depth_path_1\": {\"img1\": \"img\"},\n",
                "        #         \"depth_path_2\": {\"img2\": \"img\"},\n",
                "        #     },\n",
                "        #     \"out_map\": {\n",
                "        #         \"depth_path_1\": \"depth1\",\n",
                "        #         \"depth_path_2\": \"depth2\",\n",
                "        #     },\n",
                "        # },\n",
                "        \"content_learner\": {\n",
                "            \"target\": \"src.learners.ContentLearner\",\n",
                "            \"out_map\": {\"content_path\": \"content\"},\n",
                "        },\n",
                "    },\n",
                "    encoder={\n",
                "        \"target\": \"src.models.backbone.BackBone\",\n",
                "        \"params\": {\n",
                "            \"enc_name\": \"ConvNeXt\",\n",
                "        },\n",
                "    },\n",
                ")\n",
                "ln.set_devices([0, 1])\n",
                "\n",
                "for batch1, batch2 in zip(dl1, dl2):\n",
                "    batch = {**batch1, **batch2}\n",
                "    out = ln(batch)\n",
                "    break"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ClassLearner"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Usage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.datasets import ImageNetClassify\n",
                "from torch.utils.data import DataLoader\n",
                "from src.learners import ClassLearner\n",
                "from src.models import BackBone\n",
                "\n",
                "bs = 32\n",
                "ds = ImageNetClassify(\"./data/ImageNet-2012/\")\n",
                "dl = DataLoader(ds, bs)\n",
                "\n",
                "pre_loaded_backbone = BackBone(\"ConvNeXt\").cuda(0)\n",
                "backbone_conf = {\"target\": \"src.models.BackBone\", \"params\": {\"enc_name\": \"ConvNeXt\"}}\n",
                "\n",
                "for backbone in [pre_loaded_backbone, backbone_conf]:  # backbone can be any of these\n",
                "    ln = ClassLearner(encoder=backbone, n_classes=ds.n_classes)\n",
                "    ln.set_devices([0, 1])\n",
                "\n",
                "    # optionally freeze the encoder and load a checkpoint\n",
                "    for param in ln.encoder.parameters():\n",
                "        param.requires_grad = False\n",
                "    ln.load_ckeckpoint(\"models/mock.ckpt\")\n",
                "\n",
                "    for batch in dl:\n",
                "        out = ln(batch)\n",
                "        for k, v in out.items():\n",
                "            print(f\"{k}: {v.shape}\")\n",
                "        break"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from src.learners import ClassLearner\n",
                "from src.models import BackBone\n",
                "from mt_pipe.src.test.external.util import validate_nested_obj\n",
                "\n",
                "\n",
                "mock_batch = {\"img\": torch.Tensor(32, 3, 128, 128), \"lbl\": torch.Tensor(32)}\n",
                "expected_out_conf = {\"logits\": {\"shape\":(32, 1000), \"dtype\":\"torch.float32\"}}\n",
                "\n",
                "\n",
                "pre_loaded_backbone = BackBone(\"ConvNeXt\").cuda(0)\n",
                "backbone_conf = {\"target\": \"src.models.BackBone\", \"params\": {\"enc_name\": \"ConvNeXt\"}}\n",
                "\n",
                "for backbone in [pre_loaded_backbone, backbone_conf]:  # backbone can be any of these\n",
                "    ln = ClassLearner(encoder=backbone, n_classes=1000)\n",
                "    ln.set_devices([0, 1])\n",
                "    ln.load_ckeckpoint(\"models/mock.ckpt\")  # optionally load a checkpoint\n",
                "    out = ln(mock_batch)\n",
                "    valid, msg = validate_nested_obj(out, expected_out_conf)\n",
                "    assert valid, msg"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SegmentLearner"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Usage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.datasets import COCOSegment\n",
                "from torch.utils.data import DataLoader\n",
                "from src.learners import SegmentLearner\n",
                "from src.models import BackBone\n",
                "\n",
                "bs = 8\n",
                "ds = COCOSegment(\"./data/COCO-2017/\")\n",
                "dl = DataLoader(ds, bs)\n",
                "\n",
                "pre_loaded_backbone = BackBone(\"ConvNeXt\").cuda(0)\n",
                "backbone_conf = {\"target\": \"src.models.BackBone\", \"params\": {\"enc_name\": \"ConvNeXt\"}}\n",
                "\n",
                "for backbone in [pre_loaded_backbone, backbone_conf]:  # backbone can be any of these\n",
                "    ln = SegmentLearner(encoder=backbone, n_classes=len(ds.classes))\n",
                "    ln.set_devices([0, 1])\n",
                "    ln.load_ckeckpoint(\"models/mock.ckpt\")  # optionally load a checkpoint\n",
                "    for batch in dl:\n",
                "        out = ln(batch)\n",
                "        for k, v in out.items():\n",
                "            print(f\"{k}: {v.shape}\")\n",
                "        break"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from src.learners import SegmentLearner\n",
                "from src.models import BackBone\n",
                "from mt_pipe.src.test.external.util import validate_nested_obj\n",
                "\n",
                "mock_batch = {\n",
                "    \"img\": torch.Tensor(5, 3, 480, 640),\n",
                "    \"seg\": torch.Tensor(5, 80, 480, 640),\n",
                "}\n",
                "expected_out_conf = {\"seg\": {\"shape\":(5, 80, 480, 640), \"dtype\":\"torch.float32\"}}\n",
                "\n",
                "pre_loaded_backbone = BackBone(\"ConvNeXt\").cuda(0)\n",
                "backbone_conf = {\"target\": \"src.models.BackBone\", \"params\": {\"enc_name\": \"ConvNeXt\"}}\n",
                "\n",
                "for backbone in [pre_loaded_backbone, backbone_conf]:  # backbone can be any of these\n",
                "    ln = SegmentLearner(encoder=backbone, n_classes=80)\n",
                "    ln.set_devices([0, 1])\n",
                "    ln.load_ckeckpoint(\"models/mock.ckpt\")  # optionally load a checkpoint\n",
                "    out = ln(mock_batch)\n",
                "    valid, msg = validate_nested_obj(out, expected_out_conf)\n",
                "    assert valid, msg"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
