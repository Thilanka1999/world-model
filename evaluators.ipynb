{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from mt_pipe.src.evaluators import ClassificationEvaluator\n",
    "from src.datasets import ImageNetClassify\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import os\n",
    "\n",
    "bs = 32\n",
    "mock_batch_count = 8\n",
    "ds = ImageNetClassify(\"./data/ImageNet-2012/\", \"val\")\n",
    "sub_ds = Subset(ds, np.random.randint(0, len(ds), mock_batch_count * bs))\n",
    "dl = DataLoader(sub_ds, bs)\n",
    "\n",
    "eval_path = \"temp/class-eval\"\n",
    "os.makedirs(eval_path, exist_ok=True)\n",
    "\n",
    "ev = ClassificationEvaluator()\n",
    "ev.set_out_path(eval_path)\n",
    "\n",
    "res = []\n",
    "for batch in tqdm(dl):\n",
    "    mock_out = {\"logits\": torch.Tensor(bs, ds.n_classes)}\n",
    "    res.append(ev.process_batch(batch, mock_out))\n",
    "ev.output(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from mt_pipe.src.evaluators import SegmentationEvaluator\n",
    "from src.datasets import COCOSegment\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import os\n",
    "from src.constants import content_img_wh\n",
    "\n",
    "bs = 8\n",
    "mock_batch_count = 1\n",
    "ds = COCOSegment(\"./data/COCO-2017\", img_wh=content_img_wh, download=True)\n",
    "sub_ds = Subset(ds, np.random.randint(0, len(ds), mock_batch_count * bs))\n",
    "dl = DataLoader(sub_ds, bs)\n",
    "\n",
    "eval_path = \"temp/seg-eval\"\n",
    "os.makedirs(eval_path, exist_ok=True)\n",
    "\n",
    "ev = SegmentationEvaluator()\n",
    "ev.set_out_path(eval_path)\n",
    "\n",
    "res = []\n",
    "for batch in tqdm(dl):\n",
    "    mock_out = {\"logits\": torch.Tensor(bs, 80, 128, 128)}\n",
    "    res.append(ev.process_batch(batch, mock_out))\n",
    "ev.output(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "# from mt_pipe.src.evaluators import DepthEvaluator\n",
    "# from src.datasets import KITTIWithDepth\n",
    "# from torch.utils.data import DataLoader, Subset\n",
    "# import os\n",
    "# from src.constants import content_img_wh\n",
    "# from src.learners import DepthLearner\n",
    "# from src.models import BackBone\n",
    "\n",
    "# bs = 32\n",
    "# mock_batch_count = 8\n",
    "# ds = KITTIWithDepth(\"./data/KITTI-2012/\", img_wh=content_img_wh, download=True)\n",
    "# sub_ds = Subset(ds, np.random.randint(0, len(ds), mock_batch_count * bs))\n",
    "# dl = DataLoader(sub_ds, bs)\n",
    "\n",
    "# eval_path = \"temp/depth-eval\"\n",
    "# os.makedirs(eval_path, exist_ok=True)\n",
    "\n",
    "# ev = DepthEvaluator()\n",
    "# ev.set_out_path(eval_path)\n",
    "\n",
    "# backbone = BackBone(\"ConvNeXt\").cuda(0)\n",
    "# ln = DepthLearner(backbone)\n",
    "\n",
    "# res = []\n",
    "# for batch in tqdm(dl):\n",
    "#     out = ln(batch)\n",
    "#     res.append(ev.process_batch(batch, out))\n",
    "# ev.output(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "# from mt_pipe.src.evaluators import FlowEvaluator\n",
    "# from src.datasets import KITTIWithFlow\n",
    "# from torch.utils.data import DataLoader, Subset\n",
    "# import os\n",
    "# from src.constants import flow_img_wh\n",
    "# from src.learners import FlowLearner\n",
    "# from src.models import BackBone\n",
    "\n",
    "# bs = 4\n",
    "# mock_batch_count = 2\n",
    "# ds = KITTIWithFlow(\"./data/KITTI-2012/\", img_wh=flow_img_wh, download=True)\n",
    "# sub_ds = Subset(ds, np.random.randint(0, len(ds), mock_batch_count * bs))\n",
    "# dl = DataLoader(sub_ds, bs)\n",
    "\n",
    "# eval_path = \"temp/Flow-eval\"\n",
    "# os.makedirs(eval_path, exist_ok=True)\n",
    "\n",
    "# ev = FlowEvaluator()\n",
    "# ev.set_out_path(eval_path)\n",
    "\n",
    "# backbone = BackBone(\"ConvNeXt\").cuda(0)\n",
    "# ln = FlowLearner(backbone)\n",
    "# ln.set_devices(devices=[0, 1])\n",
    "\n",
    "# res = []\n",
    "# for batch in tqdm(dl):\n",
    "#     out = ln(batch)\n",
    "#     res.append(ev.process_batch(batch, out))\n",
    "# ev.output(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
